{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPFI7tXJG75N"
   },
   "source": [
    "# Wstęp\n",
    "Pierwsze laboratorium dotyczy wprowadzenia do środowiska PyTorch. Z uwagi na fakt, że przygotowanie środowiska może zająć dłuższą chwilę, część ta jest opisana na końcu niniejszej instrukcji i należy ją wykonać w domu (sekcja [Zadanie domowe](#homework)). Ćwiczenie to nie podlega ocenie, natomiast sugerowane jest wykonanie wszystkich poleceń w celu zapoznania się z podstawami operacji na tensorach. Przed przystąpieniem do realizacji zadań należy wykonać następujące kroki:\n",
    "\n",
    "\n",
    "1.   Uruchomić [Dysk Google](https://drive.google.com/).\n",
    "2.   Przesłać na [Dysk Google](https://drive.google.com/) plik **lab01.ipynb**.\n",
    "3.   Kliknąć prawym przyciskiem myszy na plik **lab01.ipynb** na Dysku Google i wybrać opcję **Otwórz za pomocą** a następnie **Google Colaboratory**. <br/>\n",
    "![colab.png](https://drive.google.com/uc?id=1XzvyggTWZ9j_1I3EegeXK1fu2uBAUSZi)\n",
    "4.   W menu **Google Colab** wybrać opcję **Runtime**, a następnie **Change runtime type**. <br/>\n",
    "![runtime_type.png](https://drive.google.com/uc?id=1Ldp2Je0eFZEUTyGxG3xWoYluq1jCv734)\n",
    "5.   Z rozwijanej listy **Hardware accelerator** wybrać **GPU** a następnie **SAVE**. <br/>\n",
    "![runtime_gpu.png](https://drive.google.com/uc?id=10IY3WEJJ8UVyVHhPkOgZkR6XlPakV5V5)\n",
    "6.   Na końcu należy wybrać opcję **Connect**. <br/>\n",
    "![runtime_gpu.png](https://drive.google.com/uc?id=1juOcGKNVqNJRpoKOg-KCNns15YVHI0vC) <br/>\n",
    "Gdy przycisk **Connect** zamieni się w status widoczny na poniższym obrazku, można rozpocząć pracę. <br/>\n",
    "![runtime_gpu.png](https://drive.google.com/uc?id=1w_ERPHdqD0-_fXBnI6zZR9rTPRujA3c4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tensory\n",
    "Tensory są strukturami danych, które są bardzo podobne do tablic i macierzy. W środowisku **PyTorch** tensory są wykorzystywane do zapisywania danych wejściowych i wyjściowych modelu, jak również jego parametrów. Tensory są podobne do tablic **NumPy**, z tą różnicą, że tensory mogą być uruchamiane na kartach graficznych  lub innym wyspecjalizowanym sprzęcie w celu przyspieszenia obliczeń. Przed rozpoczęciem prac należy zaimportować bibliotekę **PyTorch**. Dla przedstawienia pewnych analogii zaimportowana będzie również biblioteka **NumPy**. \n",
    "\n",
    "Ustaw kursor na polu z kodem poniżej i wciśnij przycisk ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABsAAAAYCAIAAACEIhGsAAAA+0lEQVRIDb2VMQ7DMAhFezbPyc7OWWD3Wdi5RW6RnbVSLaE44DRtrXqIIoKf/zfYedjs8ZgNtL8TRYSZEbG8BiIys6peOBtqVFUAaKD4BIARNyfWWiMlRmqtUWxCvIlrC0TomaiqUct15GT/TEz3ziuTogHg6L0jikg6Z993Iko/teBRZkccTWsSRGRd15RLRC6zI47cefa2bWkOInpOR0zXL6V4tpmNdsBzviEyc1w7J6aOjho/dv22MsuyRHWllGFlLronder0YfeY2eQON7P5p9DMJt8UrQluQuPFYzb+K0y+cb1dVZWIvE8RkYiOlfVMf+nOjEd/eXkCRZH2n46ZamIAAAAASUVORK5CYII=)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N589VyKOFCMq"
   },
   "source": [
    "import torch  # biblioteka PyTorch\n",
    "import numpy as np  # biblioteka NumPy"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAw-0AZNIFqD"
   },
   "source": [
    "## Inicjalizacja tensora\n",
    "Tensory mogą być inicjalizowane na wiele różnych sposobów. Przykładowo:\n",
    "### Bezpośrednio z listy\n",
    "Tensory mogą być tworzone bezpośrednio z listy. Typ danych jest określany automatycznie.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZWfy7d-bIAxT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c767e3db-229a-47fd-b2f6-2c26ffcf1235"
   },
   "source": [
    "data_list = [\n",
    "    [2, 5],\n",
    "    [3, 6],\n",
    "    [4, 7],\n",
    "]  # lista list z elementami w postaci liczb całkowitych\n",
    "data_tensor = torch.tensor(data_list)  # utworzenie tensora z listy\n",
    "data_tensor"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2, 5],\n",
       "        [3, 6],\n",
       "        [4, 7]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pwr5XljXqla"
   },
   "source": [
    "Utworzony tensor reprezentuje macierz o wymiarach 3x2: \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 \\\\\n",
    "3 & 6 \\\\\n",
    "4 & 7\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Wymiar tensora można sprawdzić następująco:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sNC4MYhPYwEj"
   },
   "source": [
    "data_tensor.shape  # kształt tensora"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgqvUPfnZMpa"
   },
   "source": [
    "Do elementów **shape** odwołujemy się jak w przypadku listy:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TP0h-B5aZDOf"
   },
   "source": [
    "data_tensor.shape[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kqw-OUL5ZKIs"
   },
   "source": [
    "data_tensor.shape[1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi3lQcVyWX3H"
   },
   "source": [
    "### Z tablicy NumPy\n",
    "Tensory można również tworzyć z tablicy NumPy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9_EJGZQpIC01"
   },
   "source": [
    "numpy_array = np.array(data_list)  # tablica NumPy utworzona z listy\n",
    "data_tensor = torch.from_numpy(numpy_array)  # tensor utworzony z tablicy NumPy\n",
    "data_tensor"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzmld7uPXAw5"
   },
   "source": [
    "Tensor można również skonwertować do tablicy NumPy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kirprDjqKiQ9"
   },
   "source": [
    "np_arr = data_tensor.numpy()  # tablica NumPy utworzona z tensora\n",
    "np_arr"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph0C8kRoaO_1"
   },
   "source": [
    "---\n",
    "**ZADANIE 1**\n",
    "\n",
    "Uzupełnij kod poniżej, by zmienna **my_tensor** była tensorem reprezentującym następującą macierz:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "2 & 4 & 6\\\\\n",
    "1 & 3 & 5 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-ZH8987OLoik"
   },
   "source": [
    "# my_tensor ="
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzD3gPVJbXip"
   },
   "source": [
    "---\n",
    "### Z innego tensora\n",
    "Domyślnie nowy tensor zachowuje wszystkie właściwości (kształt, typ danych) tensora przekazanego jako argument. Można nadpisać pewne właściwości podczas tworzenia."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l2ZQ9x1PbWp0"
   },
   "source": [
    "tensor_2 = torch.ones_like(\n",
    "    data_tensor\n",
    ")  # tworzenie tensora o wymiarze data_tensor wypełnionego wartościami 1\n",
    "tensor_2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sEtwjaqFeI7d"
   },
   "source": [
    "tensor_3 = torch.ones_like(\n",
    "    data_tensor, dtype=torch.float16\n",
    ")  # j.w. z wartościami typu float16\n",
    "tensor_3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oNAx1VnSeohu"
   },
   "source": [
    "tensor_4 = torch.clone(tensor_3)  # kopia tensora tensor_3\n",
    "tensor_4"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6-TwelzhYcf"
   },
   "source": [
    "W ostatnim przypadku warto zajrzeć do dokumentacji metody [torch.clone](https://pytorch.org/docs/stable/generated/torch.clone.html) oraz [detach](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF8syRqygKxN"
   },
   "source": [
    "### Z wartościami losowymi bądź stałymi\n",
    "Zmienna **tensor_shape** jest krotką, reprezentującą wymiary tensora. W poniższych funkcjach jest przekazywana jako argument, określający wymiar tworzonego tensora."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ne7cyFmFgJ_C"
   },
   "source": [
    "tensor_shape = (2, 3, 2)  # interpretacja: dwie macierze o wymiarze 3x2\n",
    "tensor_random = torch.rand(\n",
    "    tensor_shape\n",
    ")  # tensor o losowych wartościach z rozkładu jednorodnego\n",
    "tensor_random"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6wv1_bPYeHTp"
   },
   "source": [
    "tensor_ones = torch.ones(tensor_shape)  # tensor o wartościach równych 1\n",
    "tensor_ones"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TlTPsAhnj1r5"
   },
   "source": [
    "tensor_zeros = torch.zeros(tensor_shape)  # tensor o wartościach równych 0\n",
    "tensor_zeros"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGYDXMHFj_aK"
   },
   "source": [
    "---\n",
    "**ZADANIE 2**\n",
    "\n",
    "Utwórz kształt **my_shape_2**, a na jego podstawie taki tensor **my_tensor_2** o wartościach losowych, by kształt macierzy wyjściowej był taki jak podanej poniżej:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 0\\\\\n",
    "0 & 0\\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XVlHka1mLofx"
   },
   "source": [
    "# my_shape_2 =\n",
    "# my_tensor_2 ="
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTCNuFQgk71z"
   },
   "source": [
    "---\n",
    "## Atrybuty tensora\n",
    "Atrybuty tensora opisują jego kształt, typ danych oraz urządzenie, na którym tensor jest przechowywany."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LqGIHXCQLodT"
   },
   "source": [
    "tensor_random.shape  # kształt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bbzC8sKHLoa5"
   },
   "source": [
    "tensor_random.dtype  # typ danych"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xktGPB7wlutO"
   },
   "source": [
    "tensor_random.device  # urządzenie"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdDKEOXVl1dv"
   },
   "source": [
    "Tensor można przenieść do karty graficznej (GPU) lub innego urządzenia wspierającego operacje [CUDA](https://pl.wikipedia.org/wiki/CUDA) \\(np. [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)\\), o ile jest dostępne. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ah9SrgQ9mApl"
   },
   "source": [
    "if (\n",
    "    torch.cuda.is_available()\n",
    "):  # metoda sprawdzająca dostępność urządzenia CUDA (GPU lub TPU)\n",
    "    tensor_cuda = tensor_random.to(\n",
    "        \"cuda\"\n",
    "    )  # metoda przenosi tensor na wybrane urządzenie"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u5r63BEtocuJ"
   },
   "source": [
    "tensor_cuda"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0H8N3nmqXGJ"
   },
   "source": [
    "---\n",
    "**ZADANIE 3**\n",
    "\n",
    "Przenieś na GPU tensory z zadania 1 i 2."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1S2XPrKUqlbR"
   },
   "source": [
    "# zadanie 3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zskhODEWqnjR"
   },
   "source": [
    "---\n",
    "# Operacje na tensorach\n",
    "Wiele operacji na tensorach w PyTorch jest bardzo podobnych do operacji w NumPy. Niektóre przykłady będą zawierały analogie przedstawione na tablicach NumPy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSZ1eGqnrZvo"
   },
   "source": [
    "### Indeksowanie\n",
    "Najpierw utworzone zostaną dwie zmienne: **tensor** przechowująca tensor o wymiarach 3x4 oraz **array** będącą tablicą NumPy utworzoną na podstawie **tensor**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N_CoZ0uCrRfj"
   },
   "source": [
    "tensor = torch.zeros(3, 4)\n",
    "array = tensor.numpy()\n",
    "print(tensor)\n",
    "print(array)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3yFerI_sRzd"
   },
   "source": [
    "### Modyfikacja elementu o podanym indeksie\n",
    "Indeksy działają analogicznie jak w przypadku [tablic NumPy](https://numpy.org/doc/stable/reference/arrays.indexing.html). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PC9goRyJr7WY"
   },
   "source": [
    "tensor[1, 2] = 1\n",
    "array[1, 2] = 1\n",
    "print(tensor)\n",
    "print(array)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkVEnAXPtWpt"
   },
   "source": [
    "### Wydzielenie fragmentu tensora/tablicy\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wqsjuK93th4t"
   },
   "source": [
    "tensor[:, 2:]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T89uqRZZtubX"
   },
   "source": [
    "array[1:3, 1:4]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrf_H1FpuTYC"
   },
   "source": [
    "### Łączenie tensorów\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qJkjtJR7u8zt"
   },
   "source": [
    "t1 = torch.zeros(3, 2)\n",
    "t2 = torch.ones(3, 1)\n",
    "t3 = torch.cat([t1, t2, t1], dim=1)\n",
    "t3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZXvyJlhqxPY"
   },
   "source": [
    "---\n",
    "**ZADANIE 4**\n",
    "\n",
    "Zdefiniuj w postaci tensorów macierze A i B:\n",
    "\n",
    "$A = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 1 & 2\\\\\n",
    "0 & 0 & 0 & 1 & 2\\\\\n",
    "0 & 0 & 0 & 1 & 2\\\\\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$B = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 3 & 4 & 0\\\\\n",
    "0 & 0 & 3 & 4 & 0\\\\\n",
    "0 & 0 & 3 & 4 & 0\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Wykorzystując poznane operacje tensorowe na macierzach A i B, utwórz tensor C, reprezentujący następującą macierz:\n",
    "$C = \\begin{bmatrix}\n",
    "1 & 2 & 3 & 4\\\\\n",
    "1 & 2 & 3 & 4\\\\\n",
    "1 & 2 & 3 & 4\\\\\n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fs3TS35kuI95"
   },
   "source": [
    "# zadanie 4"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pbKHZ2Kt-2l"
   },
   "source": [
    "---\n",
    "### Mnożenie tensorów\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWt4oOMOwL0J"
   },
   "source": [
    "# zdefiniowanie 3 przykładowych tensorów\n",
    "t1 = torch.tensor([[1, 2], [3, 4], [2, 3]])\n",
    "t2 = torch.tensor([[2, 5], [3, 6], [4, 7]])\n",
    "t3 = torch.tensor([[2, 3]])\n",
    "\n",
    "# mnożenie dwóch tensorów (Uwaga! To nie jest mnożenie macierzowe znane z algebry!)\n",
    "t4 = t1.mul(t2)\n",
    "t5 = t1.mul(t3)\n",
    "\n",
    "# mnożenie macierzy przez liczbę\n",
    "t6 = t1.mul(5)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ix895XVuzb4j"
   },
   "source": [
    "# alternatywnie dla powyższych operatorów, można zapisać:\n",
    "t4 = t1 * t2\n",
    "t5 = t1 * t3\n",
    "t6 = t1 * 5\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3Zag88N6006n"
   },
   "source": [
    "# transpozycja macierzy\n",
    "print(t1)\n",
    "print(t1.T)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9v1IXGt0Dl9"
   },
   "source": [
    "---\n",
    "**ZADANIE 5**\n",
    "\n",
    "Zdefiniuj t3 jako tensor [[2,3,4]] i powtórz powyższe operacje korzystające z t3. Co możesz zrobić z tensorem t3, żeby operacje wykonały się prawidłowo? Co się stanie, jeśli przeniesiesz wyłącznie t3 na GPU i powtórzysz operacje, które wykonywały się prawidłowo?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0OGqBDpC2EAd"
   },
   "source": [
    "# zadanie 5"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHfM5C1Yzcvh"
   },
   "source": [
    "---\n",
    "### Mnożenie macierzowe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TqFbk2B90EMw"
   },
   "source": [
    "# Mnożenie macierzowe wykonywane jest w następujący sposób:\n",
    "print(\"t1: \", t1)\n",
    "print(t2)\n",
    "print(t2.T)\n",
    "print(t1.matmul(t2.T))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MwJdlffv0-li"
   },
   "source": [
    "# Zapis alternatywny:\n",
    "print(t1 @ t2.T)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53wbnT4k1UOE"
   },
   "source": [
    "### Operacje \"w miejscu\" (in-place)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WVvrR4iE1ZYS"
   },
   "source": [
    "# Uwaga! Operacje w miejscu pomagają oszczędzić pamięć, ale mogą nadpisać wartości potrzebne do wyznaczania gradientu.\n",
    "# Więcej informacji można znaleźć tu: https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd\n",
    "\n",
    "# Operacje w miejscu są zdefiniowane z sufiksem \"_\"\n",
    "print(t1)\n",
    "t1.add_(5)\n",
    "print(t1)\n",
    "t1.mul_(2)\n",
    "print(t1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxPGNEJ_CYsn"
   },
   "source": [
    "### Pełna lista operacji tensorowych\n",
    "\n",
    "Z pełną listą operacji tensorowych można zapoznać się tutaj:\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html#\n",
    "\n",
    "---\n",
    "**ZADANIE 6**\n",
    "\n",
    "Na podstawie [dokumentacji PyTorch](https://pytorch.org/docs/stable/torch.html#) znajdź operator, przy pomocy którego zrealizujesz następujące przekształcenia:\n",
    "\n",
    "A.\n",
    "$\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9 \\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 3 \\\\\n",
    "0 & 5 & 0 \\\\\n",
    "7 & 0 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "B.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 1 & 4 & 3\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "C.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "8 & 9 & 7 & 8 & 9\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "D.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "18 & 26 & 22 & 25 & 22\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "E.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "F.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "False & True & True & False & False\\\\\n",
    "True & False & False & True & True\\\\\n",
    "False & True & False & False & False\\\\\n",
    "False & True & False & True & True\\\\\n",
    "False & True & True & True & False\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "G.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "8 & 5 & 3 & 2 & 1\\\\\n",
    "9 & 8 & 5 & 4 & 2\\\\\n",
    "7 & 4 & 3 & 2 & 1\\\\\n",
    "8 & 7 & 6 & 3 & 2\\\\\n",
    "9 & 6 & 5 & 2 & 1\\\\\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 3 & 0 & 4\\\\\n",
    "0 & 4 & 3 & 2 & 1\\\\\n",
    "1 & 0 & 4 & 3 & 2\\\\\n",
    "4 & 1 & 3 & 2 & 0\\\\\n",
    "3 & 2 & 1 & 4 & 0\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "H.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "8 & 5 \\\\\n",
    "9 & 8 \\\\\n",
    "7 & 4 \\\\\n",
    "8 & 7 \\\\\n",
    "9 & 6 \\\\\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "0 & 4 \\\\\n",
    "1 & 0 \\\\\n",
    "4 & 1 \\\\\n",
    "3 & 2 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "I.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "2 & 7 & 15 & 18 & 19\\\\\n",
    "9 & 11 & 15 & 20 & 28\\\\\n",
    "4 & 11 & 12 & 14 & 17\\\\\n",
    "2 & 9 & 12 & 18 & 26\\\\\n",
    "1 & 6 & 12 & 21 & 23\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "J.\n",
    "$\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 3 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 2 & 3 & 3 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "K.\n",
    "$\\begin{bmatrix}\n",
    "2 & 5 & 8 & 3 & 1\\\\\n",
    "9 & 2 & 4 & 5 & 8\\\\\n",
    "4 & 7 & 1 & 2 & 3\\\\\n",
    "2 & 7 & 3 & 6 & 8\\\\\n",
    "1 & 5 & 6 & 9 & 2\\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 8 & 5 & 2\\\\\n",
    "8 & 5 & 4 & 2 & 9\\\\\n",
    "3 & 2 & 1 & 7 & 4\\\\\n",
    "8 & 6 & 3 & 7 & 2\\\\\n",
    "2 & 9 & 6 & 5 & 1\\\\\n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jhLYW0xQCNkT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ab16b4cb-b824-4a22-c6dc-38bcdf3aa5f5"
   },
   "source": [
    "baseTensor = torch.tensor(\n",
    "    [\n",
    "        [2, 5, 8, 3, 1],\n",
    "        [9, 2, 4, 5, 8],\n",
    "        [4, 7, 1, 2, 3],\n",
    "        [2, 7, 3, 6, 8],\n",
    "        [1, 5, 6, 9, 2],\n",
    "    ]\n",
    ")\n",
    "# A.\n",
    "ta = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "ta0 = torch.tensor([[1, 0, 1], [0, 1, 0], [1, 0, 1]])\n",
    "ta = ta * ta0\n",
    "print(\"A: \", ta)\n",
    "\n",
    "# B.\n",
    "tb = torch.argmax(baseTensor, dim=1)\n",
    "print(\"B: \", tb)\n",
    "\n",
    "# C. Max from each row\n",
    "tc, y = torch.max(baseTensor, dim=1)\n",
    "print(\"C: \", tc)\n",
    "\n",
    "# D. Sum each Col\n",
    "td = torch.sum(baseTensor, dim=0)\n",
    "print(\"D: \", td)\n",
    "\n",
    "# E. Unique Values\n",
    "te = torch.unique(baseTensor)\n",
    "print(\"E: \", te)\n",
    "\n",
    "# F. Bigger than 5\n",
    "threshold = 5\n",
    "tf = baseTensor >= threshold\n",
    "print(\"F: \", tf)\n",
    "\n",
    "# G.\n",
    "tg = torch.sort(baseTensor, descending=True)\n",
    "print(\"G: \", tg.values, \",\\n\", tg.indices)\n",
    "\n",
    "# H.\n",
    "th = torch.sort(baseTensor, descending=True)\n",
    "print(\"H: \", th.values[:, :2], \",\\n\", th.indices[:, :2])\n",
    "\n",
    "# I.Add current cell to next and sum is next cell cumsum\n",
    "ti = torch.cumsum(baseTensor, dim=1)\n",
    "print(\"I: \", ti)\n",
    "\n",
    "# J. make 2d array into 1d array\n",
    "tj = torch.flatten(torch.tensor([[1, 2], [2, 3], [3, 4]]))\n",
    "print(\"J: \", tj)\n",
    "\n",
    "# K. reverse in x axis\n",
    "tk = torch.fliplr(baseTensor)\n",
    "print(\"K: \", tk)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A:  tensor([[1, 0, 3],\n",
      "        [0, 5, 0],\n",
      "        [7, 0, 9]])\n",
      "B:  tensor([2, 0, 1, 4, 3])\n",
      "C:  tensor([8, 9, 7, 8, 9])\n",
      "D:  tensor([18, 26, 22, 25, 22])\n",
      "E:  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "F:  tensor([[False,  True,  True, False, False],\n",
      "        [ True, False, False,  True,  True],\n",
      "        [False,  True, False, False, False],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True,  True,  True, False]])\n",
      "G:  tensor([[8, 5, 3, 2, 1],\n",
      "        [9, 8, 5, 4, 2],\n",
      "        [7, 4, 3, 2, 1],\n",
      "        [8, 7, 6, 3, 2],\n",
      "        [9, 6, 5, 2, 1]]) ,\n",
      " tensor([[2, 1, 3, 0, 4],\n",
      "        [0, 4, 3, 2, 1],\n",
      "        [1, 0, 4, 3, 2],\n",
      "        [4, 1, 3, 2, 0],\n",
      "        [3, 2, 1, 4, 0]])\n",
      "H:  tensor([[8, 5],\n",
      "        [9, 8],\n",
      "        [7, 4],\n",
      "        [8, 7],\n",
      "        [9, 6]]) ,\n",
      " tensor([[2, 1],\n",
      "        [0, 4],\n",
      "        [1, 0],\n",
      "        [4, 1],\n",
      "        [3, 2]])\n",
      "I:  tensor([[ 2,  7, 15, 18, 19],\n",
      "        [ 9, 11, 15, 20, 28],\n",
      "        [ 4, 11, 12, 14, 17],\n",
      "        [ 2,  9, 12, 18, 26],\n",
      "        [ 1,  6, 12, 21, 23]])\n",
      "J:  tensor([1, 2, 2, 3, 3, 4])\n",
      "K:  tensor([[1, 3, 8, 5, 2],\n",
      "        [8, 5, 4, 2, 9],\n",
      "        [3, 2, 1, 7, 4],\n",
      "        [8, 6, 3, 7, 2],\n",
      "        [2, 9, 6, 5, 1]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jpef8xqKiyz"
   },
   "source": [
    "<a name=\"homework\"></a>\n",
    "# Zadanie domowe\n",
    "\n",
    "W ramach zadania domowego należy przygotować środowisko uruchomieniowe dla PyTorch. W tym celu należy zainstalować następujące elementy:\n",
    "\n",
    "\n",
    "*   [Python (wersja 3.x)](https://www.python.org/)\n",
    "*   [Sterowniki NVIDIA](https://www.nvidia.com/Download/index.aspx)\n",
    "*   [CUDA Toolkit 9.2-11.0](https://developer.nvidia.com/cuda-zone)\n",
    "*   [PyTorch 1.7.1](https://pytorch.org/)\n",
    "\n",
    "Dla osób nieposiadających GPU zalecane jest korzystanie z Google Colab. \n",
    "\n",
    "Przydatne instrukcje dla następujących systemów:\n",
    "\n",
    "\n",
    "*   [Ubuntu 20.04](https://varhowto.com/install-pytorch-ubuntu-20-04/)\n",
    "*   [Windows 10](https://pub.towardsai.net/installing-pytorch-with-cuda-support-on-windows-10-a38b1134535e)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}
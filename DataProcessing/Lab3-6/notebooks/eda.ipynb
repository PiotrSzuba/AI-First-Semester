{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/output/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ile znajduje się w zbiorze cech kategorycznych, a ile numerycznych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba cech kategorycznych: 11\n",
      "Liczba cech numerycznych: 6\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "numerical_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "print(f\"Liczba cech kategorycznych: {len(categorical_features)}\")\n",
    "print(f\"Liczba cech numerycznych: {len(numerical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Czy zmienna wyjściowa jest kategoryczna, czy numeryczna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_variable_type = df[\"sentiment\"].dtype\n",
    "print(f\"Typ zmiennej wyjściowej: {output_variable_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienna wyjściowa jest typu kategorycznego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Czy i ile w zbiorze jest brakujących wartości? Dla jakich zmiennych? Co z tego wynika?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba brakujących wartości: 42\n",
      "Brakujące wartości dla poszczególnych cech:\n",
      "reviewerName     9\n",
      "reviewText      22\n",
      "summary         11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values_count = missing_values.sum()\n",
    "missing_values_per_feature = missing_values[missing_values > 0]\n",
    "\n",
    "print(f\"Liczba brakujących wartości: {missing_values_count}\")\n",
    "print(\"Brakujące wartości dla poszczególnych cech:\")\n",
    "print(missing_values_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                 0\n",
       "vote                    0\n",
       "image                   0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "reviewerName            9\n",
       "reviewText             22\n",
       "summary                11\n",
       "unixReviewTime          0\n",
       "category                0\n",
       "sentiment               0\n",
       "sentiment_numerical     0\n",
       "textToSummaryRatio      0\n",
       "reviewAge               0\n",
       "hasImage                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Może to utrudnić dalszą analizę dodatkowo może to spowodować gorsze wyniki analizy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Czy któreś z cech są skorelowane? Co z tego może wynikać?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "strong_correlation_threshold = 0.7\n",
    "\n",
    "strong_correlations = correlation_matrix[\n",
    "    abs(correlation_matrix) > strong_correlation_threshold\n",
    "]\n",
    "print(strong_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która? Czy któraś nie koreluje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reviewText\"] = df[\"reviewText\"].fillna(\"\")\n",
    "\n",
    "df[\"wordCount\"] = df[\"reviewText\"].apply(lambda x: len(x.split()))\n",
    "df[\"uniqueWordRatio\"] = df[\"reviewText\"].apply(\n",
    "    lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0\n",
    ")\n",
    "df[\"exclamationCount\"] = df[\"reviewText\"].apply(lambda x: x.count(\"!\"))\n",
    "df[\"questionCount\"] = df[\"reviewText\"].apply(lambda x: x.count(\"?\"))\n",
    "df[\"spaceCount\"] = df[\"reviewText\"].apply(lambda x: x.count(\" \"))\n",
    "df[\"averageWordLength\"] = df[\"reviewText\"].apply(\n",
    "    lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
    ")\n",
    "\n",
    "capital_letters_count = sum(1 for c in df[\"reviewText\"] if c.isupper())\n",
    "total_letters_count = sum(1 for c in df[\"reviewText\"] if c.isalpha())\n",
    "\n",
    "df[\"capitalLetterRatio\"] = (\n",
    "    capital_letters_count / total_letters_count if total_letters_count > 0 else 0\n",
    ")\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "correlations_with_output = correlation_matrix[\"sentiment_numerical\"]\n",
    "print(correlations_with_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nic nie koreluje ze sobą. Jest overall ale to dlatego że wartość sentiment_numerical bezpośrednio wychodzi z wartości overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Głębsza analiza:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Częstość występowania słów kluczowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def get_words(val):\n",
    "    reviews = df[df[\"sentiment_numerical\"] == val]\n",
    "\n",
    "    word_freq = Counter()\n",
    "\n",
    "    for review_text in reviews[\"reviewText\"]:\n",
    "        words = word_tokenize(review_text.lower())\n",
    "\n",
    "        filtered_words = [\n",
    "            word for word in words if word.isalnum() and word not in stop_words\n",
    "        ]\n",
    "\n",
    "        word_freq.update(filtered_words)\n",
    "\n",
    "    return word_freq\n",
    "\n",
    "\n",
    "negative_words = get_words(-1)\n",
    "neutral_words = get_words(0)\n",
    "positive_words = get_words(1)\n",
    "\n",
    "word_count = df[\"reviewText\"].apply(lambda x: len(word_tokenize(x.lower())))\n",
    "df[\"negative_word_freq\"] = df[\"reviewText\"].apply(\n",
    "    lambda x: sum(\n",
    "        [\n",
    "            negative_words[word]\n",
    "            for word in word_tokenize(x.lower())\n",
    "            if word.isalnum() and word not in stop_words\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "df[\"neutral_word_freq\"] = df[\"reviewText\"].apply(\n",
    "    lambda x: sum(\n",
    "        [\n",
    "            neutral_words[word]\n",
    "            for word in word_tokenize(x.lower())\n",
    "            if word.isalnum() and word not in stop_words\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "df[\"positive_word_freq\"] = df[\"reviewText\"].apply(\n",
    "    lambda x: sum(\n",
    "        [\n",
    "            positive_words[word]\n",
    "            for word in word_tokenize(x.lower())\n",
    "            if word.isalnum() and word not in stop_words\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return a / b if b != 0 else 0\n",
    "\n",
    "\n",
    "df[\"negative_word_freq_normalized\"] = df.apply(\n",
    "    lambda x: safe_divide(x[\"negative_word_freq\"], x[\"wordCount\"]), axis=1\n",
    ")\n",
    "df[\"neutral_word_freq_normalized\"] = df.apply(\n",
    "    lambda x: safe_divide(x[\"neutral_word_freq\"], x[\"wordCount\"]), axis=1\n",
    ")\n",
    "df[\"positive_word_freq_normalized\"] = df.apply(\n",
    "    lambda x: safe_divide(x[\"positive_word_freq\"], x[\"wordCount\"]), axis=1\n",
    ")\n",
    "\n",
    "df = df.drop([\"negative_word_freq\", \"neutral_word_freq\", \"positive_word_freq\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_word_freq = Counter(negative_words)\n",
    "neutral_word_freq = Counter(neutral_words)\n",
    "positive_word_freq = Counter(positive_words)\n",
    "\n",
    "print(negative_word_freq)\n",
    "print(neutral_word_freq)\n",
    "print(positive_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlations_with_output = correlation_matrix[\"sentiment_numerical\"]\n",
    "print(correlations_with_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza N-gramów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return list(ngrams(words, n))\n",
    "\n",
    "\n",
    "def get_ngram_words(val, n):\n",
    "    reviews = df[df[\"sentiment_numerical\"] == val]\n",
    "    ngram_freq = Counter()\n",
    "\n",
    "    for ngrams in reviews[f\"{n}-grams\"]:\n",
    "        ngram_freq.update(ngrams)\n",
    "\n",
    "    return ngram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"2-grams\"] = df[\"reviewText\"].apply(lambda x: generate_ngrams(x, 2))\n",
    "\n",
    "negative_bigrams = get_ngram_words(-1, 2)\n",
    "neutral_bigrams = get_ngram_words(0, 2)\n",
    "positive_bigrams = get_ngram_words(1, 2)\n",
    "\n",
    "df[\"negative_bigram_freq\"] = df[\"2-grams\"].apply(\n",
    "    lambda x: sum([negative_bigrams[bigram] for bigram in x])\n",
    ")\n",
    "df[\"neutral_bigram_freq\"] = df[\"2-grams\"].apply(\n",
    "    lambda x: sum([neutral_bigrams[bigram] for bigram in x])\n",
    ")\n",
    "df[\"positive_bigram_freq\"] = df[\"2-grams\"].apply(\n",
    "    lambda x: sum([positive_bigrams[bigram] for bigram in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"3-grams\"] = df[\"reviewText\"].apply(lambda x: generate_ngrams(x, 3))\n",
    "\n",
    "negative_trigrams = get_ngram_words(-1, 3)\n",
    "neutral_trigrams = get_ngram_words(0, 3)\n",
    "positive_trigrams = get_ngram_words(1, 3)\n",
    "\n",
    "df[\"negative_trigram_freq\"] = df[\"3-grams\"].apply(\n",
    "    lambda x: sum([negative_trigrams[trigrams] for trigrams in x])\n",
    ")\n",
    "df[\"neutral_trigram_freq\"] = df[\"3-grams\"].apply(\n",
    "    lambda x: sum([neutral_trigrams[trigrams] for trigrams in x])\n",
    ")\n",
    "df[\"positive_trigram_freq\"] = df[\"3-grams\"].apply(\n",
    "    lambda x: sum([positive_trigrams[trigrams] for trigrams in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"2-grams\", \"3-grams\"], axis=1)\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "correlations_with_output = correlation_matrix[\"sentiment_numerical\"]\n",
    "print(correlations_with_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza składniowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def count_noun_phrases(text):\n",
    "    doc = nlp(text)\n",
    "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    return len(noun_phrases)\n",
    "\n",
    "\n",
    "def count_adjectives(text):\n",
    "    doc = nlp(text)\n",
    "    adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
    "    return len(adjectives)\n",
    "\n",
    "\n",
    "def count_adj_noun_relations(text):\n",
    "    doc = nlp(text)\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\" and token.head.pos_ == \"NOUN\":\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['noun_phrase_count'] = df['reviewText'].apply(count_noun_phrases)\n",
    "# df['adjective_count'] = df['reviewText'].apply(count_adjectives)\n",
    "# df['adj_noun_relation_count'] = df['reviewText'].apply(count_adj_noun_relations)\n",
    "\n",
    "\"\"\"\n",
    "40 min for results:\n",
    "\n",
    "overall                          0.944986\n",
    "verified                         0.212653\n",
    "unixReviewTime                   0.154403\n",
    "sentiment_numerical              1.000000\n",
    "textToSummaryRatio              -0.103077\n",
    "reviewAge                       -0.154403\n",
    "hasImage                         0.081214\n",
    "wordCount                       -0.093744\n",
    "uniqueWordRatio                  0.154451\n",
    "exclamationCount                -0.053314\n",
    "questionCount                   -0.120817\n",
    "spaceCount                      -0.094012\n",
    "averageWordLength                0.053776\n",
    "capitalLetterRatio                    NaN\n",
    "negative_word_freq_normalized   -0.025649\n",
    "neutral_word_freq_normalized     0.036695\n",
    "positive_word_freq_normalized    0.143411\n",
    "negative_bigram_freq            -0.116719\n",
    "neutral_bigram_freq             -0.124113\n",
    "positive_bigram_freq            -0.065687\n",
    "negative_trigram_freq           -0.131534\n",
    "neutral_trigram_freq            -0.159608\n",
    "positive_trigram_freq            0.082245\n",
    "noun_phrase_count               -0.091599\n",
    "adjective_count                 -0.073501\n",
    "adj_noun_relation_count         -0.066093\n",
    "Name: sentiment_numerical, dtype: float64\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix = df.corr()\n",
    "# correlations_with_output = correlation_matrix['sentiment_numerical']\n",
    "# print(correlations_with_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall                          0.944986 \\\n",
    "verified                         0.212653 \\\n",
    "unixReviewTime                   0.154403 \\\n",
    "sentiment_numerical              1.000000 \\\n",
    "textToSummaryRatio              -0.103077 \\\n",
    "reviewAge                       -0.154403 \\\n",
    "hasImage                         0.081214 \\\n",
    "wordCount                       -0.093744 \\\n",
    "uniqueWordRatio                  0.154451 \\\n",
    "exclamationCount                -0.053314 \\\n",
    "questionCount                   -0.120817 \\\n",
    "spaceCount                      -0.094012 \\\n",
    "averageWordLength                0.053776 \\\n",
    "capitalLetterRatio                    NaN \\\n",
    "negative_word_freq_normalized   -0.025649 \\\n",
    "neutral_word_freq_normalized     0.036695 \\\n",
    "positive_word_freq_normalized    0.143411 \\\n",
    "negative_bigram_freq            -0.116719 \\\n",
    "neutral_bigram_freq             -0.124113 \\\n",
    "positive_bigram_freq            -0.065687 \\\n",
    "negative_trigram_freq           -0.131534 \\\n",
    "neutral_trigram_freq            -0.159608 \\\n",
    "positive_trigram_freq            0.082245 \\\n",
    "noun_phrase_count               -0.091599 \\\n",
    "adjective_count                 -0.073501 \\\n",
    "adj_noun_relation_count         -0.066093 \\\n",
    "Name: sentiment_numerical, dtype: float64\n",
    "\n",
    "Podsumowując korzystając z statystyki nie udało się uzyskać wyników które wskazywały by wpływ danej cechy na wartość sentymentu\\\n",
    "\n",
    "Zalecane jest użycie uczenia maszynowego w kolejnym etapie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c5547c",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946b8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Piotr Szuba\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4b0120d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d39eb517",
   "metadata": {},
   "source": [
    "# 2. Zadania w przetwarzaniu grafów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39f0ed6",
   "metadata": {},
   "source": [
    "## 2.1. Uczenie reprezentacji wierzchołków\n",
    "\n",
    "W poniższych rozważaniach będziemy się skupiać na zadaniu uczenia reprezentacji dla wierzchołków w grafie (ang. *node embedding*). Celem będzie znalezienie funkcji $h: \\mathcal{V} \\to \\mathbb{R}^d$, która dla każdego wierzchołka $u$ wyznaczy (obliczy) jego wektor reprezentacji $\\mathbf{z}_u$. Zobaczymy, że za pomocą reprezentacji wierzchołków możemy również uzyskać reprezentacje krawędzi oraz całych grafów. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4af598bd",
   "metadata": {},
   "source": [
    "## 2.2. Zadania uczenia maszynowego na grafach\n",
    "\n",
    "Zanim przejdziemy do omówienia konkretnych metod uczenia reprezentacji grafów, przygotujemy sobie narzędzia (funkcje) do ewaluacji otrzymanych wektorów reprezentacji trzech najpopularniejszych zadaniach związanych z przetwarzaniem grafów:\n",
    "\n",
    "1. Klasyfikacja wierzchołków\n",
    "2. Predykcja krawędzi\n",
    "3. Klasyfikacja grafów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc4ec5b",
   "metadata": {},
   "source": [
    "## 2.3. Klasyfikacja wierzchołków\n",
    "\n",
    "Zakładamy, że każdy wierzchołek w grafie może zostać skojarzony z pewną klasą – np.:\n",
    "- w sieci społecznej – płeć,\n",
    "- w cząsteczkach chemicznych – rodzaj atomu). \n",
    "\n",
    "Korzystając z wektorów reprezentacji $\\mathbf{Z}$, uczymy klasyfikator $f$ (np. liniowy lub sieć MLP) przewidywania klasy $c_u$ danego wierzchołka $u$, tzn. $f(z_u) = c_u$ (ang. **node classification**). Musimy podzielić zbiór wierzchołków na treningowe oraz testowe. Klasyfikator uczymy na wektorach reprezentacji i klasach wierzchołków treningowych, a metryki ewaluacyjne wyliczamy uwzględniając predykcje klasyfikatora na wektorach reprezentacji wierzchołków ze zbioru testowego. \n",
    "\n",
    "Często w grafach tylko niewielka część wierzchołków jest oznaczona (ma przypisane klasy).\n",
    "\n",
    "**Uwaga:** W trakcie uczenia wektorów reprezentacji pomijamy informację o klasach wierzchołków (*unsupervised learning*)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdd86f30",
   "metadata": {},
   "source": [
    "### Zadanie 2.1. (1.5 pkt)\n",
    "Zaimplementuj poniższą funkcję `evaluate_node_classification`, która zweryfikuje jakość podanych wektorów reprezentacji wierzchołków `z` w zadaniu klasyfikacji wierzchołków:\n",
    "\n",
    "- podziel wierzchołki grafu na zbiór treningowy oraz testowy, uwzględniając rozmiar zbioru testowego `test_size`,\n",
    "- zastosuj klasyfikator regresji logistycznej na wektorach reprezentacji oraz etykietach wierzchołków,\n",
    "- oblicz metrykę AUC na zbiorze treningowym oraz testowym.\n",
    "\n",
    "\n",
    "**Uwaga:** Pomijamy w tym zadaniu fakt, że wiele zbiorów ma zdefiniowany \"odgórnie\" podział wierzchołków - zobacz atrybuty `train_mask`, `val_mask` oraz `test_mask` w obiekcie `Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3876045e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1f9f17d1aaa95ef7f26b9180066982",
     "grade": true,
     "grade_id": "evaluate_node_classification",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def evaluate_node_classification(\n",
    "    data: Data,\n",
    "    z: torch.Tensor,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, float]:\n",
    "    y = data.y.numpy()\n",
    "    train_mask, test_mask = train_test_split(range(len(y)), test_size=test_size, stratify=y)\n",
    "\n",
    "    z_train = z[train_mask]\n",
    "    z_test = z[test_mask]\n",
    "    y_train = data.y[train_mask]\n",
    "    y_test = data.y[test_mask]\n",
    "\n",
    "    classifier = LogisticRegression(multi_class='ovr')\n",
    "    classifier.fit(z_train, y_train)\n",
    "\n",
    "    y_train_pred = classifier.predict_proba(z_train)\n",
    "    y_test_pred = classifier.predict_proba(z_test)\n",
    "\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred, multi_class='ovr')\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred, multi_class='ovr')\n",
    "    \n",
    "    evaluation_results = {\n",
    "        'train_auc': auc_train,\n",
    "        'test_auc': auc_test\n",
    "    }\n",
    "    return evaluation_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1426339",
   "metadata": {},
   "source": [
    "Zweryfikujmy, że funkcja działa na losowo zainicjalizowanej macierzy wektorów reprezentacji wierzchołków i zbiorze Cora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ab6ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_auc': 0.7433846284967799, 'test_auc': 0.5187286084390209}\n"
     ]
    }
   ],
   "source": [
    "def test_evaluate_node_classification():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "    z = torch.randn(data.num_nodes, 128)\n",
    "\n",
    "    metrics = evaluate_node_classification(data=data, z=z)\n",
    "\n",
    "    assert \"train_auc\" in metrics\n",
    "    assert \"test_auc\" in  metrics\n",
    "\n",
    "    print(metrics)\n",
    "    \n",
    "    \n",
    "test_evaluate_node_classification()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b895ff9",
   "metadata": {},
   "source": [
    "## 2.4. Predykcja krawędzi\n",
    "\n",
    "W wielu przypadkach możemy założyć, że nie posiadamy pełnej informacji o strukturze grafu, tzn. nie obserwujemy w zbiorze wszystkich krawędzi, które w rzeczywistości istnieją w danym grafie. Możemy jednak wyuczyć model, który uzupełni brakujące krawędzie (ang. **link prediction**). \n",
    "\n",
    "Zbiór krawędzi grafu dzielimy na zbiór treningowy oraz testowy. Krawędzie ze zbioru testowego *usuwamy z grafu*, aby były nieobserwowane w trakcie uczenia wektorów reprezentacji. W niektórych wariantach tego zadania, staramy się również podzielić wierzchołki tak, aby krawędzie testowe występowały tylko między wybranym podzbiorem wierzchołków (które również na czas uczenia usuwamy) – ten scenariusz jednak nie będziemy stosować w ramach zajęć.\n",
    "\n",
    "Na tym etapie możemy zauważyć pewnien problem – mamy tylko informację o istniejących w grafie krawędziach. Nie wiadomo jak wyuczyć model klasyfikatora? Potrzebowalibyśmy jeszcze informacji o krawędziach, które nie istnieją w grafie, wtedy możemy uznać istniejące krawędzie (przykłady pozytywne) jako klasę $1$, a nieistniejące (przykłady negatywne) jako klasę $0$. \n",
    "\n",
    "Dokładnie tak rozwiążemy nasz problem – każdej krawędzi w obecnym zbiorze treningowym i testowym przypisujemy klasę $1$. Następnie dla każdej krawędzi losujemy ze zbioru wszystkich możliwych krawędzi, taką która nie istnieje w danym grafie i przypisujemy jej klasę $0$ (ang. *balanced negative sampling*).\n",
    "\n",
    "Wybór odpowiednich negatywnych przypadków jest bardziej skomplikowany i istnieje wiele strategii losowania, jednak pozostaniemy przy najprostszym scenariuszu losując krawędź zgodnie z rozkładem jednostajnym (tzn. każdy wybór tak samo prawdopodobny).\n",
    "\n",
    "Kolejnym zagadnieniem jest jak otrzymać wektor reprezentacji dla krawędzi, skoro założyliśmy, że korzystamy z wektorów dla wierzchołków? Tutaj również mamy wiele możliwości, jednak najpopularniejszym rozwiązaniem jest wykorzystanie jednej z następujących transformacji wektorów reprezentacji wierzchołków $z_{uv} = z_u \\circ z_v$, gdzie $\\circ: \\mathcal{V} \\times \\mathcal{V} \\to \\mathbb{R}^{d}$. Metody te zostały zaproponowane w pracy [Node2vec](https://arxiv.org/pdf/1607.00653.pdf) i są aplikowane na każdym elemencie wektora reprezentacji osobno (ang. *element-wise*):\n",
    "\n",
    "| Nazwa | Wzór  |\n",
    "|-------|-------|\n",
    "| Średnia  | $$ z_{uv} = \\frac{z_u + z_v}{2}$$ |\n",
    "| Hadamard | $$ z_{uv} = z_u * z_v$$ |\n",
    "| L1       | $$ z_{uv} = |z_u - z_v|$$ |\n",
    "| L2       | $$ z_{uv} = |z_u - z_v|^2$$ |\n",
    "\n",
    "Po przekształceniu wektorów reprezentacji wierzchołków na wektory krawędzi, możemy wyuczyć klasyfikator binarny na wektorach krawędzi ze zbioru treningowego (uwzględniając przypadki pozytywne i negatywne), a następnie wyliczyć wartości miar ewaluacyjnych w oparciu o predykcje klasyfikatora na wektorach krawędzi ze zbioru testowego."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed8d3351",
   "metadata": {},
   "source": [
    "### Zadanie 2.2 (5 pkt)\n",
    "Zaimplementuj następujące funkcje:\n",
    "\n",
    "- `prepare_train_test_sets` (2 pkt):\n",
    "    - podaną listę krawędzi `edge_index` podziel na zbiór treningowy (`train_edges_pos`) oraz testowy (`test_edges_pos`) uwzględniając wielkość zbioru testowego `test_size`,\n",
    "    - dla każdej krawędzi wylosuj przypadek negatywny: `train_edges_neg` oraz `test_edges_neg` (zobacz funkcję `negative_sampling` z biblioteki PyTorch-Geometric),\n",
    "    - utwórz listę (tensor) krawędzi treningowych `train_edges` (konkatenacja `train_edges_pos` oraz `train_edges_neg`) o wymiarach `2 x łączna liczba krawędzi`,\n",
    "    - utwórz taką samą listę dla krawędzi testowych `test_edges`,\n",
    "    - utwórz wektory etykiet (zera i jedynki): `y_train` oraz `y_test`.\n",
    "    \n",
    "- `transform_to_edge_embeddings` (2 pkt):\n",
    "    - dla podanej listy krawędzi `edge_index` oraz wektorów reprezentacji wierzchołków `z` obliczy reprezentacje krawędzi\n",
    "    - argument `transformation_name` wyznacza metodę transformacji: \"average\", \"hadamard\", \"L1\" lub \"L2\" (zgodnie z powyższą tabelką)\n",
    "\n",
    "- `evalute_link_prediction` (1 pkt):\n",
    "    - dla podanych: listy krawędzi treningowych `train_edges` (wraz z `y_train`) oraz testowych `test_edges` (wraz z `y_test`), metody transformacji do reprezentacji krawędzi `transformation_name` oraz reprezentacji wierzchołków `z`, przeprowadzi ewaluację tych reprezentacji w zadaniu predykcji krawędzi\n",
    "    - zastosuj klasyfikator regresji logistycznej\n",
    "    - oblicz miary AUC dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0ec9dc9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8da3c78f9c1895c28b6233573584c61f",
     "grade": true,
     "grade_id": "prepare_train_test_sets",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def prepare_train_test_sets(\n",
    "    edge_index: torch.Tensor,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    num_nodes = edge_index.max().item() + 1\n",
    "    \n",
    "    edge_index_T = edge_index.t()\n",
    "    edges_pos_train, edges_pos_test = train_test_split(edge_index_T, test_size=test_size, random_state=42)\n",
    "    train_edges_pos = edges_pos_train.t()\n",
    "    test_edges_pos = edges_pos_test.t()\n",
    "\n",
    "    train_edges_neg = negative_sampling(edge_index=train_edges_pos, num_nodes=num_nodes)\n",
    "    test_edges_neg = negative_sampling(edge_index=test_edges_pos, num_nodes=num_nodes)\n",
    "\n",
    "    train_edges = torch.cat([train_edges_pos, train_edges_neg], dim=1)\n",
    "    test_edges = torch.cat([test_edges_pos, test_edges_neg], dim=1)\n",
    "    \n",
    "    y_train = torch.cat([torch.ones(train_edges_pos.size(1)), torch.zeros(train_edges_neg.size(1))], dim=0)\n",
    "    y_test = torch.cat([torch.ones(test_edges_pos.size(1)), torch.zeros(test_edges_neg.size(1))], dim=0)\n",
    "\n",
    "    return {\n",
    "        \"train_edges_pos\": train_edges_pos,\n",
    "        \n",
    "        \"train_edges\": train_edges,\n",
    "        \"y_train\": y_train,\n",
    "        \n",
    "        \"test_edges\": test_edges,\n",
    "        \"y_test\": y_test,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_prepare_train_test_sets():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    \n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "\n",
    "    train_size = 0.6\n",
    "    out = prepare_train_test_sets(\n",
    "        edge_index=data.edge_index,\n",
    "        test_size=1 - train_size,\n",
    "    )\n",
    "\n",
    "    num_train_edges_pos = int(train_size * data.num_edges)\n",
    "    num_test_edges_pos = data.num_edges - num_train_edges_pos\n",
    "    \n",
    "    assert out[\"train_edges_pos\"].shape[1] == num_train_edges_pos\n",
    "    \n",
    "    assert out[\"train_edges\"].shape == (2, 2 * num_train_edges_pos)\n",
    "    assert out[\"y_train\"].shape == (2 * num_train_edges_pos,)\n",
    "    \n",
    "    assert out[\"test_edges\"].shape == (2, 2 * num_test_edges_pos)\n",
    "    assert out[\"y_test\"].shape == (2 * num_test_edges_pos,)\n",
    "    \n",
    "    \n",
    "test_prepare_train_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed8fa2ce",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b70b36b888d03164b52d810dd8c57778",
     "grade": true,
     "grade_id": "transform_to_edge_embeddings",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_edge_embeddings(\n",
    "    edge_index: torch.Tensor,\n",
    "    z: torch.Tensor,\n",
    "    transformation_name: str,\n",
    ") -> torch.Tensor:\n",
    "    source_nodes_embeddings = z[edge_index[0, :]]\n",
    "    target_nodes_embeddings = z[edge_index[1, :]]\n",
    "    \n",
    "    if transformation_name == \"average\":\n",
    "        edge_embeddings = (source_nodes_embeddings + target_nodes_embeddings) / 2\n",
    "    elif transformation_name == \"hadamard\":\n",
    "        edge_embeddings = source_nodes_embeddings * target_nodes_embeddings\n",
    "    elif transformation_name == \"L1\":\n",
    "        edge_embeddings = torch.abs(source_nodes_embeddings - target_nodes_embeddings)\n",
    "    elif transformation_name == \"L2\":\n",
    "        edge_embeddings = (source_nodes_embeddings - target_nodes_embeddings) ** 2\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transformation name: {transformation_name}\")\n",
    "\n",
    "    return edge_embeddings\n",
    "\n",
    "\n",
    "def test_transform_to_edge_embeddings():\n",
    "    ei = torch.tensor([[0], [1]])\n",
    "    z = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "    ])\n",
    "    \n",
    "    assert (transform_to_edge_embeddings(ei, z, \"average\") == torch.tensor([[2.5, 3.5, 4.5]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"hadamard\") == torch.tensor([[4, 10, 18]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"L1\") == torch.tensor([[3, 3, 3]])).all()\n",
    "    assert (transform_to_edge_embeddings(ei, z, \"L2\") == torch.tensor([[9, 9, 9]])).all()\n",
    "    \n",
    "    \n",
    "test_transform_to_edge_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14891030",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f523b30f7c3ad14b2cdc57c967dc914",
     "grade": true,
     "grade_id": "evaluate_link_prediction",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_auc': 0.6113308489222387, 'test_auc': 0.5770839065682785}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_link_prediction(\n",
    "    train_edges: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    test_edges: torch.Tensor,\n",
    "    y_test: torch.Tensor,\n",
    "    transformation_name: str,\n",
    "    z: torch.Tensor,\n",
    ") -> Dict[str, float]:\n",
    "    train_edges_emb = transform_to_edge_embeddings(train_edges, z, transformation_name)\n",
    "    test_edges_emb = transform_to_edge_embeddings(test_edges, z, transformation_name)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_edges_emb, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict_proba(train_edges_emb)[:, 1]\n",
    "    y_test_pred = model.predict_proba(test_edges_emb)[:, 1]\n",
    "    \n",
    "    auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        'train_auc': auc_train,\n",
    "        'test_auc': auc_test\n",
    "    }\n",
    "    \n",
    "    \n",
    "def test_evaluate_link_prediction():\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    \n",
    "    data = Planetoid(root=\"./data/\", name=\"Cora\")[0]\n",
    "\n",
    "    out = prepare_train_test_sets(edge_index=data.edge_index)\n",
    "    \n",
    "    z = torch.randn(data.num_nodes, 128)\n",
    "    \n",
    "    metrics = evaluate_link_prediction(\n",
    "        train_edges=out[\"train_edges\"],\n",
    "        y_train=out[\"y_train\"],\n",
    "        test_edges=out[\"test_edges\"],\n",
    "        y_test=out[\"y_test\"],\n",
    "        transformation_name=\"average\",\n",
    "        z=z,\n",
    "    )\n",
    "    \n",
    "    assert \"train_auc\" in metrics.keys()\n",
    "    assert \"test_auc\" in metrics.keys()\n",
    "    \n",
    "    print(metrics)\n",
    "\n",
    "\n",
    "test_evaluate_link_prediction()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f64dc6",
   "metadata": {},
   "source": [
    "## 2.5. Klasyfikacja grafów\n",
    "\n",
    "Zadanie to jest podobne do klasyfikacji wierzchołków, przy czym tutaj klasa jest przypisana do całego grafu. Przykładem może być klasyfikacja białek (reprezentowanych jako grafy). \n",
    "\n",
    "Podejście jest analogiczne jak w punkcie **2.3**. Zbiór grafów dzielimy na zbiór treningowy oraz testowy i uczymy odpowiedni klasyfikator. Jedynym zagadnieniem, które musimy rozwiązać jest sposób uzyskania wektora reprezentacji dla całego grafu na podstawie wektorów reprezentacji pojedynczych wierzchołków. Będziemy rozważać proste przekształcenia, które będą agregować wektory wierzchołków w jeden wektor opisujacy cały graf:\n",
    "\n",
    "- uśrednianie: $z_\\mathcal{G} = \\frac{1}{|\\mathcal{V}|} \\sum_{u \\in \\mathcal{V}} z_u$\n",
    "- redukcja max (ang. **max pooling**): $z_\\mathcal{G} = \\max_i \\{z_1^{(i)}, z_2^{(i)}, \\ldots, z_{|\\mathcal{V}|}^{(i)} \\} \\;\\forall i = 1 \\ldots d$, gdzie $z_u^{(i)}$ oznacza $i$-ty element wektora $z_u$,\n",
    "- redukcja min (ang. **min pooling**): $z_\\mathcal{G} = \\min_i \\{z_1^{(i)}, z_2^{(i)}, \\ldots, z_{|\\mathcal{V}|}^{(i)} \\} \\;\\forall i = 1 \\ldots d$\n",
    "\n",
    "Możemy również zastosować inne strategie wyznaczania wektora opisującego cały graf, ale więcej o tym na następnym wykładzie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6caa8c81",
   "metadata": {},
   "source": [
    "### Zadanie 2.3. (3.5 pkt)\n",
    "Zaimplementuj funkcje:\n",
    "\n",
    "- `transform_to_graph_embedding` (1.5 pkt):\n",
    "    - dla podanej macierzy reprezentacji wierzchołków `z` wyznaczy wektor reprezentacji całego grafu\n",
    "    - argument `transformation_name` wyznacza metodę transformacji: \"average\", \"max_pooling\", \"min_pooling\"\n",
    "    \n",
    "- `evaluate_graph_classification` (2 pkt):\n",
    "    - dla podanej listy macierzy reprezentacji grafów `z`, wektora etykiet grafów `y` oraz metody transformacji `transformation_name`, przeprowadzi ewaluację reprezentacji w zadaniu klasyfikacji grafów\n",
    "    - podziel grafy na zbiór treningowy oraz testowy, gdzie wielkość zbioru testowego jest określona za pomocą parametru `test_size`,\n",
    "    - przetransformuj listę macierzy reprezentacji wierzchołków w jedną macierz reprezentacji grafów,\n",
    "    - zastosuj klasyfikator regresji logistycznej\n",
    "    - oblicz miary AUC dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7041c832",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8af24ae7b1cbc8cd7a0a29b5f0112fb9",
     "grade": true,
     "grade_id": "transform_to_graph_embedding",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_graph_embedding(\n",
    "    z: torch.Tensor,\n",
    "    transformation_name: str,\n",
    ") -> torch.Tensor:\n",
    "    if transformation_name == \"average\":\n",
    "        return z.mean(dim=0)\n",
    "    elif transformation_name == \"max_pooling\":\n",
    "        return z.max(dim=0)[0]\n",
    "    elif transformation_name == \"min_pooling\":\n",
    "        return z.min(dim=0)[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transformation: {transformation_name}\")\n",
    "\n",
    "        \n",
    "\n",
    "def test_transform_to_graph_embedding():\n",
    "    z = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9],\n",
    "    ])\n",
    "    \n",
    "    assert (transform_to_graph_embedding(z, \"average\") == torch.tensor([4, 5, 6])).all()\n",
    "    assert (transform_to_graph_embedding(z, \"max_pooling\") == torch.tensor([7, 8, 9])).all()\n",
    "    assert (transform_to_graph_embedding(z, \"min_pooling\") == torch.tensor([1, 2, 3])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd10ab3a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae4567ab06aed96be0a4cd47e134bb79",
     "grade": true,
     "grade_id": "evaluate_graph_classification",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_auc': 0.9237988978654822, 'test_auc': 0.5085761696598391}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def evaluate_graph_classification(\n",
    "    z: List[torch.Tensor],\n",
    "    y: torch.Tensor,\n",
    "    transformation_name: str,\n",
    "    test_size: float = 0.4,\n",
    ") -> Dict[str, float]:\n",
    "    z_graphs = [transform_to_graph_embedding(z_i, transformation_name) for z_i in z]\n",
    "    z_graphs = torch.stack(z_graphs)\n",
    "    \n",
    "    z_train, z_test, y_train, y_test = train_test_split(z_graphs, y, test_size=test_size, random_state=42)\n",
    "    classifier = LogisticRegression(multi_class='ovr')\n",
    "    classifier.fit(z_train, y_train)\n",
    "    \n",
    "    y_train_pred = classifier.predict_proba(z_train)\n",
    "    y_test_pred = classifier.predict_proba(z_test)\n",
    "    \n",
    "    auc_train = roc_auc_score(y_train, y_train_pred, multi_class=\"ovr\")\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred, multi_class=\"ovr\")\n",
    "    \n",
    "    return {\n",
    "        'train_auc': auc_train,\n",
    "        'test_auc': auc_test\n",
    "    }\n",
    "    \n",
    "    \n",
    "def test_evaluate_graph_classification():\n",
    "    from torch_geometric.datasets import TUDataset\n",
    "    \n",
    "    enzymes = TUDataset(root=\"./data\", name=\"ENZYMES\")\n",
    "    \n",
    "    y = torch.tensor([e.y for e in enzymes])\n",
    "    z = [torch.randn(e.num_nodes, 128) for e in enzymes]\n",
    "\n",
    "    metrics = evaluate_graph_classification(z, y, \"average\")\n",
    "    \n",
    "    assert \"train_auc\" in metrics.keys()\n",
    "    assert \"test_auc\" in metrics.keys()\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "    \n",
    "test_evaluate_graph_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60061bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
